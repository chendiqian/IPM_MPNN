{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c613b1ca-4366-4c13-b0d4-47e581195d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy_solver.linprog import linprog\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "import torch\n",
    "from scipy.linalg import LinAlgWarning\n",
    "from scipy.optimize._optimize import OptimizeWarning\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4266622-739c-4a38-ba80-4dd6f008093f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "equality = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb555547-2d9c-4caf-9d8a-d52d748adeed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    \"\"\"\n",
    "    Container for a graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    number_of_nodes : int\n",
    "        The number of nodes in the graph.\n",
    "    edges : set of tuples (int, int)\n",
    "        The edges of the graph, where the integers refer to the nodes.\n",
    "    degrees : numpy array of integers\n",
    "        The degrees of the nodes in the graph.\n",
    "    neighbors : dictionary of type {int: set of ints}\n",
    "        The neighbors of each node in the graph.\n",
    "    \"\"\"\n",
    "    def __init__(self, number_of_nodes, edges, degrees, neighbors):\n",
    "        self.number_of_nodes = number_of_nodes\n",
    "        self.edges = edges\n",
    "        self.degrees = degrees\n",
    "        self.neighbors = neighbors\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        The number of nodes in the graph.\n",
    "        \"\"\"\n",
    "        return self.number_of_nodes\n",
    "\n",
    "    def greedy_clique_partition(self):\n",
    "        \"\"\"\n",
    "        Partition the graph into cliques using a greedy algorithm.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of sets\n",
    "            The resulting clique partition.\n",
    "        \"\"\"\n",
    "        cliques = []\n",
    "        leftover_nodes = (-self.degrees).argsort().tolist()\n",
    "\n",
    "        while leftover_nodes:\n",
    "            clique_center, leftover_nodes = leftover_nodes[0], leftover_nodes[1:]\n",
    "            clique = {clique_center}\n",
    "            neighbors = self.neighbors[clique_center].intersection(leftover_nodes)\n",
    "            densest_neighbors = sorted(neighbors, key=lambda x: -self.degrees[x])\n",
    "            for neighbor in densest_neighbors:\n",
    "                # Can you add it to the clique, and maintain cliqueness?\n",
    "                if all([neighbor in self.neighbors[clique_node] for clique_node in clique]):\n",
    "                    clique.add(neighbor)\n",
    "            cliques.append(clique)\n",
    "            leftover_nodes = [node for node in leftover_nodes if node not in clique]\n",
    "\n",
    "        return cliques\n",
    "\n",
    "    @staticmethod\n",
    "    def erdos_renyi(number_of_nodes, edge_probability, random):\n",
    "        \"\"\"\n",
    "        Generate an Erdös-Rényi random graph with a given edge probability.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        number_of_nodes : int\n",
    "            The number of nodes in the graph.\n",
    "        edge_probability : float in [0,1]\n",
    "            The probability of generating each edge.\n",
    "        random : numpy.random.RandomState\n",
    "            A random number generator.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Graph\n",
    "            The generated graph.\n",
    "        \"\"\"\n",
    "        edges = set()\n",
    "        degrees = np.zeros(number_of_nodes, dtype=int)\n",
    "        neighbors = {node: set() for node in range(number_of_nodes)}\n",
    "        for edge in combinations(np.arange(number_of_nodes), 2):\n",
    "            if random.uniform() < edge_probability:\n",
    "                edges.add(edge)\n",
    "                degrees[edge[0]] += 1\n",
    "                degrees[edge[1]] += 1\n",
    "                neighbors[edge[0]].add(edge[1])\n",
    "                neighbors[edge[1]].add(edge[0])\n",
    "        graph = Graph(number_of_nodes, edges, degrees, neighbors)\n",
    "        return graph\n",
    "\n",
    "    @staticmethod\n",
    "    def barabasi_albert(number_of_nodes, affinity, random):\n",
    "        \"\"\"\n",
    "        Generate a Barabási-Albert random graph with a given edge probability.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        number_of_nodes : int\n",
    "            The number of nodes in the graph.\n",
    "        affinity : integer >= 1\n",
    "            The number of nodes each new node will be attached to, in the sampling scheme.\n",
    "        random : numpy.random.RandomState\n",
    "            A random number generator.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Graph\n",
    "            The generated graph.\n",
    "        \"\"\"\n",
    "        assert affinity >= 1 and affinity < number_of_nodes\n",
    "\n",
    "        edges = set()\n",
    "        degrees = np.zeros(number_of_nodes, dtype=int)\n",
    "        neighbors = {node: set() for node in range(number_of_nodes)}\n",
    "        for new_node in range(affinity, number_of_nodes):\n",
    "            # first node is connected to all previous ones (star-shape)\n",
    "            if new_node == affinity:\n",
    "                neighborhood = np.arange(new_node)\n",
    "            # remaining nodes are picked stochastically\n",
    "            else:\n",
    "                neighbor_prob = degrees[:new_node] / (2*len(edges))\n",
    "                neighborhood = random.choice(new_node, affinity, replace=False, p=neighbor_prob)\n",
    "            for node in neighborhood:\n",
    "                edges.add((node, new_node))\n",
    "                degrees[node] += 1\n",
    "                degrees[new_node] += 1\n",
    "                neighbors[node].add(new_node)\n",
    "                neighbors[new_node].add(node)\n",
    "\n",
    "        graph = Graph(number_of_nodes, edges, degrees, neighbors)\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5253b78c-64f5-4b2d-b4d9-fd7107bbdebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b2dfbe-1ca0-4fda-b22f-b356c25a8e9b",
   "metadata": {},
   "source": [
    "# Setcover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6115eac-c19c-4b60-9ce6-b36e30434643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_setcover(nrows, ncols, density, rng):\n",
    "    \"\"\"\n",
    "    Generates a setcover instance with specified characteristics, and writes\n",
    "    it to a file in the LP format.\n",
    "\n",
    "    Approach described in:\n",
    "    E.Balas and A.Ho, Set covering algorithms using cutting planes, heuristics,\n",
    "    and subgradient optimization: A computational study, Mathematical\n",
    "    Programming, 12 (1980), 37-60.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nrows : int\n",
    "        Desired number of rows\n",
    "    ncols : int\n",
    "        Desired number of columns\n",
    "    density: float between 0 (excluded) and 1 (included)\n",
    "        Desired density of the constraint matrix\n",
    "    rng: numpy.random.RandomState\n",
    "        Random number generator\n",
    "    \"\"\"\n",
    "    nnzrs = int(nrows * ncols * density)\n",
    "\n",
    "    assert nnzrs >= nrows  # at least 1 col per row\n",
    "    assert nnzrs >= 2 * ncols  # at leats 2 rows per col\n",
    "\n",
    "    # compute number of rows per column\n",
    "    indices = rng.choice(ncols, size=nnzrs)  # random column indexes\n",
    "    indices[:2 * ncols] = np.repeat(np.arange(ncols), 2)  # force at leats 2 rows per col\n",
    "    _, col_nrows = np.unique(indices, return_counts=True)\n",
    "\n",
    "    # for each column, sample random rows\n",
    "    indices[:nrows] = rng.permutation(nrows) # force at least 1 column per row\n",
    "    i = 0\n",
    "    indptr = [0]\n",
    "    for n in col_nrows:\n",
    "\n",
    "        # empty column, fill with random rows\n",
    "        if i >= nrows:\n",
    "            indices[i:i+n] = rng.choice(nrows, size=n, replace=False)\n",
    "\n",
    "        # partially filled column, complete with random rows among remaining ones\n",
    "        elif i + n > nrows:\n",
    "            remaining_rows = np.setdiff1d(np.arange(nrows), indices[i:nrows], assume_unique=True)\n",
    "            indices[nrows:i+n] = rng.choice(remaining_rows, size=i+n-nrows, replace=False)\n",
    "\n",
    "        i += n\n",
    "        indptr.append(i)\n",
    "\n",
    "    # file.write(\"minimize\\nOBJ:\")\n",
    "    # file.write(\"\".join([f\" +{c[j]} x{j+1}\" for j in range(ncols)]))\n",
    "\n",
    "    # file.write(\"\\n\\nsubject to\\n\")\n",
    "    # for i in range(nrows):\n",
    "    #     row_cols_str = \"\".join([f\" +1 x{j+1}\" for j in indices[indptr[i]:indptr[i+1]]])\n",
    "    #     file.write(f\"C{i}:\" + row_cols_str + f\" >= 1\\n\")\n",
    "\n",
    "    # file.write(\"\\nbinary\\n\")\n",
    "    # file.write(\"\".join([f\" x{j+1}\" for j in range(ncols)]))\n",
    "\n",
    "    # min   c^tx\n",
    "    # s.t. Ax>=b\n",
    "    #       x>=0\n",
    "    \n",
    "    # objective coefficients\n",
    "    c = rng.rand(ncols)\n",
    "\n",
    "    # sparce CSC to sparse CSR matrix\n",
    "    A = scipy.sparse.csc_matrix(\n",
    "            (np.ones(len(indices), dtype=float), indices, indptr),\n",
    "            shape=(nrows, ncols)).toarray()\n",
    "    \n",
    "    A = -A\n",
    "    b = np.ones(nrows, dtype=np.float32) * -1\n",
    "    if equality:\n",
    "        A = np.concatenate([A, np.eye(nrows, dtype=np.float32)], axis=1)\n",
    "        c = np.concatenate([c, np.zeros(nrows, dtype=np.float32)], axis=0)\n",
    "    \n",
    "    return A, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f427d670-75f4-4085-9c67-2631b013ba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"error\")\n",
    "\n",
    "ips = []\n",
    "max_iter = 12000\n",
    "num = 10000\n",
    "\n",
    "pkg_idx = 0\n",
    "\n",
    "success_cnt = 0\n",
    "fail_cnt = 0\n",
    "\n",
    "for i in tqdm(range(max_iter)):\n",
    "    A, b, c = generate_setcover(nrows=np.random.randint(30, 50), ncols=np.random.randint(50, 70), density=0.1, rng=rng)\n",
    "    \n",
    "    try:\n",
    "        if equality:\n",
    "            A_eq = A\n",
    "            b_eq = b\n",
    "            A_ub = None\n",
    "            b_ub = None\n",
    "        else:\n",
    "            A_eq = None\n",
    "            b_eq = None\n",
    "            A_ub = A\n",
    "            b_ub = b\n",
    "        res = linprog(c, \n",
    "                A_ub=A_ub,\n",
    "                b_ub=b_ub,\n",
    "                A_eq=A_eq, b_eq=b_eq, bounds=None, method='interior-point')\n",
    "    except (LinAlgWarning, OptimizeWarning):\n",
    "        fail_cnt += 1\n",
    "        continue\n",
    "    else:\n",
    "        if res.success:\n",
    "            ips.append((torch.from_numpy(A).to(torch.float), torch.from_numpy(b).to(torch.float), torch.from_numpy(c).to(torch.float)))\n",
    "            success_cnt += 1\n",
    "\n",
    "    if len(ips) >= 1000 or success_cnt == num:\n",
    "        with gzip.open(f'ineq_small_instances/raw/instance_{pkg_idx}.pkl.gz', \"wb\") as file:\n",
    "            pickle.dump(ips, file)\n",
    "            pkg_idx += 1\n",
    "        ips = []\n",
    "\n",
    "    if success_cnt >= num:\n",
    "        break\n",
    "\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feba305-fe78-4c36-9e05-c9925320ce8f",
   "metadata": {},
   "source": [
    "# Indset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09ad177c-1119-4c1a-96b4-57a5fe8b33ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_indset(graph):\n",
    "    \"\"\"\n",
    "    Generate a Maximum Independent Set (also known as Maximum Stable Set) instance\n",
    "    in CPLEX LP format from a previously generated graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : Graph\n",
    "        The graph from which to build the independent set problem.\n",
    "    \"\"\"\n",
    "    cliques = graph.greedy_clique_partition()\n",
    "    inequalities = set(graph.edges)\n",
    "    for clique in cliques:\n",
    "        clique = tuple(sorted(clique))\n",
    "        for edge in combinations(clique, 2):\n",
    "            inequalities.remove(edge)\n",
    "        if len(clique) > 1:\n",
    "            inequalities.add(clique)\n",
    "\n",
    "    # Put trivial inequalities for nodes that didn't appear\n",
    "    # in the constraints, otherwise SCIP will complain\n",
    "    used_nodes = set()\n",
    "    for group in inequalities:\n",
    "        used_nodes.update(group)\n",
    "    for node in range(nnodes):\n",
    "        if node not in used_nodes:\n",
    "            inequalities.add((node,))\n",
    "    \n",
    "    c = -np.ones(len(graph))\n",
    "    A, b = np.zeros((len(inequalities), len(graph))), np.ones(len(inequalities))\n",
    "    for ineq, group in enumerate(inequalities):\n",
    "        A[ineq, sorted(group)] = 1.\n",
    "\n",
    "    return A, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e184b0b-4aab-44f4-946c-ca608eebe7d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 12309/15000 [01:34<00:20, 129.67it/s]\n",
      "Exception ignored in: <function Socket.__del__ at 0x7fb11eec3370>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chendi/miniconda3/envs/ipmgnn/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 182, in __del__\n",
      "    warn(\n",
      "ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x7fb11c1cc2e0>\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"error\")\n",
    "\n",
    "ips = []\n",
    "max_iter = 15000\n",
    "num = 10000\n",
    "\n",
    "pkg_idx = 0\n",
    "\n",
    "success_cnt = 0\n",
    "fail_cnt = 0\n",
    "\n",
    "for i in tqdm(range(max_iter)):\n",
    "    graph = Graph.barabasi_albert(number_of_nodes=50, affinity=2, random=rng)\n",
    "    A, b, c = generate_indset(graph)\n",
    "    \n",
    "    try:\n",
    "        if equality:\n",
    "            A_eq = A\n",
    "            b_eq = b\n",
    "            A_ub = None\n",
    "            b_ub = None\n",
    "        else:\n",
    "            A_eq = None\n",
    "            b_eq = None\n",
    "            A_ub = A\n",
    "            b_ub = b\n",
    "        res = linprog(c, \n",
    "                A_ub=A_ub,\n",
    "                b_ub=b_ub,\n",
    "                A_eq=A_eq, b_eq=b_eq, bounds=None, method='interior-point')\n",
    "    except (LinAlgWarning, OptimizeWarning):\n",
    "        fail_cnt += 1\n",
    "        continue\n",
    "    else:\n",
    "        if res.success:\n",
    "            ips.append((torch.from_numpy(A).to(torch.float), torch.from_numpy(b).to(torch.float), torch.from_numpy(c).to(torch.float)))\n",
    "            success_cnt += 1\n",
    "\n",
    "    if len(ips) >= 1000 or success_cnt == num:\n",
    "        with gzip.open(f'ineq_small_indset_instances/raw/instance_{pkg_idx}.pkl.gz', \"wb\") as file:\n",
    "            pickle.dump(ips, file)\n",
    "            pkg_idx += 1\n",
    "        ips = []\n",
    "\n",
    "    if success_cnt >= num:\n",
    "        break\n",
    "\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b10bae9-954f-4f8d-891b-c11ef61e61d2",
   "metadata": {},
   "source": [
    "# Cauctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7bedbd6f-fcb7-4091-b509-2db2882c5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cauctions(n_items, n_bids, rng, min_value=1, max_value=100,\n",
    "                    value_deviation=0.5, add_item_prob=0.7, max_n_sub_bids=5,\n",
    "                    additivity=0.2, budget_factor=1.5, resale_factor=0.5,\n",
    "                    integers=False, warnings=False):\n",
    "    \"\"\"\n",
    "    Generate a Combinatorial Auction problem following the 'arbitrary' scheme found in section 4.3. of\n",
    "        Kevin Leyton-Brown, Mark Pearson, and Yoav Shoham. (2000).\n",
    "        Towards a universal test suite for combinatorial auction algorithms.\n",
    "        Proceedings of ACM Conference on Electronic Commerce (EC-00) 66-76.\n",
    "\n",
    "    Saves it as a CPLEX LP file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_items : int\n",
    "        The number of items.\n",
    "    n_bids : int\n",
    "        The number of bids.\n",
    "    rng : numpy.random.RandomState\n",
    "        A random number generator.\n",
    "    min_value : int\n",
    "        The minimum resale value for an item.\n",
    "    max_value : int\n",
    "        The maximum resale value for an item.\n",
    "    value_deviation : int\n",
    "        The deviation allowed for each bidder's private value of an item, relative from max_value.\n",
    "    add_item_prob : float in [0, 1]\n",
    "        The probability of adding a new item to an existing bundle.\n",
    "    max_n_sub_bids : int\n",
    "        The maximum number of substitutable bids per bidder (+1 gives the maximum number of bids per bidder).\n",
    "    additivity : float\n",
    "        Additivity parameter for bundle prices. Note that additivity < 0 gives sub-additive bids, while additivity > 0 gives super-additive bids.\n",
    "    budget_factor : float\n",
    "        The budget factor for each bidder, relative to their initial bid's price.\n",
    "    resale_factor : float\n",
    "        The resale factor for each bidder, relative to their initial bid's resale value.\n",
    "    integers : logical\n",
    "        Should bid's prices be integral ?\n",
    "    warnings : logical\n",
    "        Should warnings be printed ?\n",
    "    \"\"\"\n",
    "\n",
    "    assert min_value >= 0 and max_value >= min_value\n",
    "    assert add_item_prob >= 0 and add_item_prob <= 1\n",
    "\n",
    "    def choose_next_item(bundle_mask, interests, compats, add_item_prob, rng):\n",
    "        n_items = len(interests)\n",
    "        prob = (1 - bundle_mask) * interests * compats[bundle_mask, :].mean(axis=0)\n",
    "        prob /= prob.sum()\n",
    "        return rng.choice(n_items, p=prob)\n",
    "\n",
    "    # common item values (resale price)\n",
    "    values = min_value + (max_value - min_value) * rng.rand(n_items)\n",
    "\n",
    "    # item compatibilities\n",
    "    compats = np.triu(rng.rand(n_items, n_items), k=1)\n",
    "    compats = compats + compats.transpose()\n",
    "    compats = compats / compats.sum(1)\n",
    "\n",
    "    bids = []\n",
    "    n_dummy_items = 0\n",
    "\n",
    "    # create bids, one bidder at a time\n",
    "    while len(bids) < n_bids:\n",
    "\n",
    "        # bidder item values (buy price) and interests\n",
    "        private_interests = rng.rand(n_items)\n",
    "        private_values = values + max_value * value_deviation * (2 * private_interests - 1)\n",
    "\n",
    "        # substitutable bids of this bidder\n",
    "        bidder_bids = {}\n",
    "\n",
    "        # generate initial bundle, choose first item according to bidder interests\n",
    "        prob = private_interests / private_interests.sum()\n",
    "        item = rng.choice(n_items, p=prob)\n",
    "        bundle_mask = np.full(n_items, 0)\n",
    "        bundle_mask[item] = 1\n",
    "\n",
    "        # add additional items, according to bidder interests and item compatibilities\n",
    "        while rng.rand() < add_item_prob:\n",
    "            # stop when bundle full (no item left)\n",
    "            if bundle_mask.sum() == n_items:\n",
    "                break\n",
    "            item = choose_next_item(bundle_mask, private_interests, compats, add_item_prob, rng)\n",
    "            bundle_mask[item] = 1\n",
    "\n",
    "        bundle = np.nonzero(bundle_mask)[0]\n",
    "\n",
    "        # compute bundle price with value additivity\n",
    "        price = private_values[bundle].sum() + np.power(len(bundle), 1 + additivity)\n",
    "        if integers:\n",
    "            price = int(price)\n",
    "\n",
    "        # drop negativaly priced bundles\n",
    "        if price < 0:\n",
    "            if warnings:\n",
    "                print(\"warning: negatively priced bundle avoided\")\n",
    "            continue\n",
    "\n",
    "        # bid on initial bundle\n",
    "        bidder_bids[frozenset(bundle)] = price\n",
    "\n",
    "        # generate candidates substitutable bundles\n",
    "        sub_candidates = []\n",
    "        for item in bundle:\n",
    "\n",
    "            # at least one item must be shared with initial bundle\n",
    "            bundle_mask = np.full(n_items, 0)\n",
    "            bundle_mask[item] = 1\n",
    "\n",
    "            # add additional items, according to bidder interests and item compatibilities\n",
    "            while bundle_mask.sum() < len(bundle):\n",
    "                item = choose_next_item(bundle_mask, private_interests, compats, add_item_prob, rng)\n",
    "                bundle_mask[item] = 1\n",
    "\n",
    "            sub_bundle = np.nonzero(bundle_mask)[0]\n",
    "\n",
    "            # compute bundle price with value additivity\n",
    "            sub_price = private_values[sub_bundle].sum() + np.power(len(sub_bundle), 1 + additivity)\n",
    "            if integers:\n",
    "                sub_price = int(sub_price)\n",
    "\n",
    "            sub_candidates.append((sub_bundle, sub_price))\n",
    "\n",
    "        # filter valid candidates, higher priced candidates first\n",
    "        budget = budget_factor * price\n",
    "        min_resale_value = resale_factor * values[bundle].sum()\n",
    "        for bundle, price in [\n",
    "            sub_candidates[i] for i in np.argsort([-price for bundle, price in sub_candidates])]:\n",
    "\n",
    "            if len(bidder_bids) >= max_n_sub_bids + 1 or len(bids) + len(bidder_bids) >= n_bids:\n",
    "                break\n",
    "\n",
    "            if price < 0:\n",
    "                if warnings:\n",
    "                    print(\"warning: negatively priced substitutable bundle avoided\")\n",
    "                continue\n",
    "\n",
    "            if price > budget:\n",
    "                if warnings:\n",
    "                    print(\"warning: over priced substitutable bundle avoided\")\n",
    "                continue\n",
    "\n",
    "            if values[bundle].sum() < min_resale_value:\n",
    "                if warnings:\n",
    "                    print(\"warning: substitutable bundle below min resale value avoided\")\n",
    "                continue\n",
    "\n",
    "            if frozenset(bundle) in bidder_bids:\n",
    "                if warnings:\n",
    "                    print(\"warning: duplicated substitutable bundle avoided\")\n",
    "                continue\n",
    "\n",
    "            bidder_bids[frozenset(bundle)] = price\n",
    "\n",
    "        # add XOR constraint if needed (dummy item)\n",
    "        if len(bidder_bids) > 2:\n",
    "            dummy_item = [n_items + n_dummy_items]\n",
    "            n_dummy_items += 1\n",
    "        else:\n",
    "            dummy_item = []\n",
    "\n",
    "        # place bids\n",
    "        for bundle, price in bidder_bids.items():\n",
    "            bids.append((list(bundle) + dummy_item, price))\n",
    "\n",
    "    bids_per_item = [[] for item in range(n_items + n_dummy_items)]\n",
    "\n",
    "    # file.write(\"maximize\\nOBJ:\")\n",
    "    # for i, bid in enumerate(bids):\n",
    "    #     bundle, price = bid\n",
    "    #     file.write(f\" +{price} x{i+1}\")\n",
    "    #     for item in bundle:\n",
    "    #         bids_per_item[item].append(i)\n",
    "\n",
    "    # file.write(\"\\n\\nsubject to\\n\")\n",
    "    # for item_bids in bids_per_item:\n",
    "    #     if item_bids:\n",
    "    #         for i in item_bids:\n",
    "    #             file.write(f\" +1 x{i+1}\")\n",
    "    #         file.write(f\" <= 1\\n\")\n",
    "\n",
    "    # file.write(\"\\nbinary\\n\")\n",
    "    # for i in range(len(bids)):\n",
    "    #     file.write(f\" x{i+1}\")\n",
    "\n",
    "    \n",
    "    # min   c^tx\n",
    "    # s.t. Ax>=b\n",
    "    #       x>=0\n",
    "\n",
    "    c = np.zeros(len(bids))\n",
    "    for i, bid in enumerate(bids):\n",
    "        bundle, price = bid\n",
    "        c[i] = -price\n",
    "        for item in bundle:\n",
    "            bids_per_item[item].append(i)\n",
    "\n",
    "    A = []\n",
    "    for item_bids in bids_per_item:\n",
    "        if item_bids:\n",
    "            row = np.zeros(len(c))\n",
    "            row[item_bids] = -1\n",
    "            A.append(row)\n",
    "    A = np.array(A)\n",
    "    b = -np.ones(A.shape[0])\n",
    "\n",
    "    return A, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d0c22580-e663-48c4-9387-b12d29b8fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items=100\n",
    "n_bids=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "baa91688-6c34-4195-9105-bbbf1af3808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b, c = generate_cauctions(n_items, n_bids, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c53eb5bb-ed09-4728-b31d-a20759e12d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, -7220.376162159035)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution = linprog(c, A_ub=-A, b_ub=-b, bounds=(0,1))\n",
    "solution.success, solution.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70957397-d822-4a34-b05d-8eeeba50214a",
   "metadata": {},
   "source": [
    "# Facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3e8ea7ae-8964-4fc2-b61f-b27752bd6812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_capacited_facility_location(n_customers, n_facilities, ratio, rng):\n",
    "    \"\"\"\n",
    "    Generate a Capacited Facility Location problem following\n",
    "        Cornuejols G, Sridharan R, Thizy J-M (1991)\n",
    "        A Comparison of Heuristics and Relaxations for the Capacitated Plant Location Problem.\n",
    "        European Journal of Operations Research 50:280-297.\n",
    "\n",
    "    Saves it as a CPLEX LP file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_customers: int\n",
    "        The desired number of customers.\n",
    "    n_facilities: int\n",
    "        The desired number of facilities.\n",
    "    ratio: float\n",
    "        The desired capacity / demand ratio.\n",
    "    rng : numpy.random.RandomState\n",
    "        A rng number generator.\n",
    "    \"\"\"\n",
    "    c_x = rng.rand(n_customers)\n",
    "    c_y = rng.rand(n_customers)\n",
    "\n",
    "    f_x = rng.rand(n_facilities)\n",
    "    f_y = rng.rand(n_facilities)\n",
    "\n",
    "    demands = rng.randint(5, 35+1, size=n_customers)\n",
    "    capacities = rng.randint(10, 160+1, size=n_facilities)\n",
    "    fixed_costs = rng.randint(100, 110+1, size=n_facilities) * np.sqrt(capacities) \\\n",
    "            + rng.randint(90+1, size=n_facilities)\n",
    "    fixed_costs = fixed_costs.astype(int)\n",
    "\n",
    "    total_demand = demands.sum()\n",
    "    total_capacity = capacities.sum()\n",
    "\n",
    "    # adjust capacities according to ratio\n",
    "    capacities = capacities * ratio * total_demand / total_capacity\n",
    "    capacities = capacities.astype(int)\n",
    "    total_capacity = capacities.sum()\n",
    "\n",
    "    # transportation costs\n",
    "    trans_costs = np.sqrt(\n",
    "            (c_x.reshape((-1, 1)) - f_x.reshape((1, -1))) ** 2 \\\n",
    "            + (c_y.reshape((-1, 1)) - f_y.reshape((1, -1))) ** 2) * 10 * demands.reshape((-1, 1))\n",
    "\n",
    "#     file.write(\"minimize\\nobj:\")\n",
    "#     file.write(\"\".join([f\" +{trans_costs[i, j]} x_{i+1}_{j+1}\" for i in range(n_customers) for j in range(n_facilities)]))\n",
    "#     file.write(\"\".join([f\" +{fixed_costs[j]} y_{j+1}\" for j in range(n_facilities)]))\n",
    "\n",
    "#     file.write(\"\\n\\nsubject to\\n\")\n",
    "#     for i in range(n_customers):\n",
    "#         file.write(f\"demand_{i+1}:\" + \"\".join([f\" -1 x_{i+1}_{j+1}\" for j in range(n_facilities)]) + f\" <= -1\\n\")\n",
    "#     for j in range(n_facilities):\n",
    "#         file.write(f\"capacity_{j+1}:\" + \"\".join([f\" +{demands[i]} x_{i+1}_{j+1}\" for i in range(n_customers)]) + f\" -{capacities[j]} y_{j+1} <= 0\\n\")\n",
    "\n",
    "#     # optional constraints for LP relaxation tightening\n",
    "#     file.write(\"total_capacity:\" + \"\".join([f\" -{capacities[j]} y_{j+1}\" for j in range(n_facilities)]) + f\" <= -{total_demand}\\n\")\n",
    "#     for i in range(n_customers):\n",
    "#         for j in range(n_facilities):\n",
    "#             file.write(f\"affectation_{i+1}_{j+1}: +1 x_{i+1}_{j+1} -1 y_{j+1} <= 0\")\n",
    "\n",
    "#     file.write(\"\\nbounds\\n\")\n",
    "#     for i in range(n_customers):\n",
    "#         for j in range(n_facilities):\n",
    "#             file.write(f\"0 <= x_{i+1}_{j+1} <= 1\\n\")\n",
    "    \n",
    "    \n",
    "    # min   c^tx\n",
    "    # s.t. Ax>=b\n",
    "    #       x>=0\n",
    "    \n",
    "    c = np.concatenate([trans_costs.flatten(), fixed_costs])\n",
    "\n",
    "    A, b = [], []\n",
    "    for i in range(n_customers):\n",
    "        row = np.zeros((n_customers, n_facilities))\n",
    "        row[i, :] = 1\n",
    "        row = np.concatenate([row.flatten(), np.zeros(n_facilities)])\n",
    "        A.append(row)\n",
    "        b.append(1)\n",
    "    for j in range(n_facilities):\n",
    "        row = np.zeros((n_customers, n_facilities))\n",
    "        row[:, j] = -demands\n",
    "        row = np.concatenate([row.flatten(), capacities])\n",
    "        A.append(row)\n",
    "        b.append(0)\n",
    "\n",
    "    A.append(np.concatenate([np.zeros(n_customers*n_facilities), capacities]))\n",
    "    b.append(total_demand)\n",
    "\n",
    "    for i in range(n_customers):\n",
    "        for j in range(n_facilities):\n",
    "            row1 = np.zeros((n_customers, n_facilities))\n",
    "            row1[i, j] = -1\n",
    "            row2 = np.zeros(n_facilities)\n",
    "            row2[j] = 1\n",
    "            row = np.concatenate([row1.flatten(), row2])\n",
    "            A.append(row)\n",
    "            b.append(0)\n",
    "            \n",
    "    A, b = np.array(A), np.array(b)\n",
    "\n",
    "    return A, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0171ea88-4ce5-43a9-a41f-f0e0e28cc0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_customers = 100\n",
    "n_facilities = 100\n",
    "ratio = 5\n",
    "\n",
    "A, b, c = generate_capacited_facility_location(n_customers, n_facilities, ratio, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "badd4b23-74ef-4593-a40f-031b5bf7b88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 18719.5521182855)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution = linprog(c, A_ub=-A, b_ub=-b, bounds=(0,1))\n",
    "solution.success, solution.fun"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
